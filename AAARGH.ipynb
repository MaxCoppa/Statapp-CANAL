{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme des données\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def file_to_dataframe(filenames): \n",
    "    \"\"\"\n",
    "    Initialize the DataFrame from a filenames \n",
    "    Parameters: \n",
    "    -----------\n",
    "    filenames: str, the name of the file\n",
    "    st: str, helps to delimites the columns of the datas because \"Correspondances_promo\n",
    "    are delimited with ';' while the other are delimited with ','.\n",
    "    \"\"\"\n",
    "    datas = pd.read_csv(filenames)\n",
    "    return datas\n",
    "\n",
    "\n",
    "def clean_dates(df):\n",
    "    \"\"\"\n",
    "    Clean the dates of the files with dates such as \"2022-11-14T00:00:00Z\" and change it into \"2022-11-14\"\n",
    "    -----------\n",
    "    df: dataframe, the dataframe that we use\n",
    "    \n",
    "    \"\"\"\n",
    "    for colu in df.columns :\n",
    "        if df[colu].dtype == object: \n",
    "            df[colu] = df[colu].str.replace('T00:00:00Z', '')\n",
    "    return(df)\n",
    "\n",
    "def change_date(st):\n",
    "    \"\"\"\n",
    "    Change a date as \"28/04/2003 00:00:00.000\" into one more precise \"2003-04-28\"\n",
    "    -----------\n",
    "    st: str, the date to change\n",
    "\n",
    "    \"\"\" \n",
    "    if type(st) != str or len(st) < 10 : \n",
    "        return(st)\n",
    "    else :\n",
    "        date = st[:10].split(\"/\")\n",
    "        return(date[2]+\"-\"+date[1]+\"-\"+date[0])\n",
    "    \n",
    "def change_dates_all(df,cols):\n",
    "    \"\"\"\n",
    "    Change the dates of some columns of a dataFrame using the function change_date\n",
    "    -----------\n",
    "    df: dataframe, the DataFrame on which we are working\n",
    "    cols: str list, a list of columns name that we want to change\n",
    "\n",
    "    \"\"\" \n",
    "    for colu in cols : \n",
    "        df[colu] = df[colu].apply(change_date)\n",
    "    return df\n",
    "\n",
    "def save_to_csv_file(df,filename):\n",
    "    \"\"\"\n",
    "    Save a dataframe on a .csv file at filename\n",
    "    ----------\n",
    "    df: dataframe, the DataFrame that you want to save\n",
    "    filename: str, the place where you want to save your data frame\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dataFrames(df1,df2,cond):\n",
    "    \"\"\"\n",
    "    Join two DataFrames on the conditions cond\n",
    "    Parameters: \n",
    "    -----------\n",
    "    df1,df2: DataFrames\n",
    "    cond: str list of the colomuns on which we want to join \n",
    "    \"\"\"\n",
    "    return pd.merge(df1, df2, on=cond, how='inner')\n",
    "\n",
    "def join_dataFrames_outer(df1,df2,cond):\n",
    "    \"\"\"\n",
    "    Join two DataFrames on the conditions cond\n",
    "    Parameters: \n",
    "    -----------\n",
    "    df1,df2: DataFrames\n",
    "    cond: str list of the colomuns on which we want to join \n",
    "    \"\"\"\n",
    "    return pd.merge(df1, df2, on=cond, how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1)\n",
    "\n",
    "def df_filter_condition(df,str_name, str_cond):\n",
    "    \"\"\"\n",
    "    This function filters the elemenent of the columns str_name with the condition ==\n",
    "    str_cond\n",
    "    \"\"\"\n",
    "    return df[df[str_name] == str_cond]\n",
    "\n",
    "\n",
    "def df_filter_begin_name(df, str_name, str_filter):\n",
    "    \"\"\"\n",
    "    This function filters the elemenent of the columns str_name which begins with \n",
    "    str_filter\n",
    "    \"\"\"\n",
    "    return df[df[str_name].str.startswith(str_filter)]\n",
    "\n",
    "\n",
    "def apply_conditions(row):\n",
    "    \"\"\"\n",
    "    This function creates the elements of a new column where the promos are put\n",
    "    together in function of some conditions.\n",
    "    \"\"\"\n",
    "    nb_days = 'NBJOUR_ODD'\n",
    "    carticle = 'CARTICLE_ODD'\n",
    "    if row['SG'] == 'Semaine généreuse':\n",
    "        return 'Semaine genéreuse'\n",
    "    elif row[nb_days] == 7 :\n",
    "        return 'ODD 7 jours autre que SG'\n",
    "    elif (row[carticle][:2] == 'EV') & (row[nb_days] == 15) :\n",
    "        return 'ODD 15 jours EV+'\n",
    "    elif (row[carticle][:2]  == 'TC') & (row[nb_days] == 15) :\n",
    "        return 'ODD 15 jours TC'\n",
    "    elif (row[carticle][:2] == 'EV') & (row[nb_days] == 21) :\n",
    "        return 'ODD 21 jours EV+ '\n",
    "    elif (row[carticle][:2] == 'TC') & (row[nb_days] == 21):\n",
    "        return 'ODD 21 jours EV+ '\n",
    "    else: \n",
    "        return 'Autres'\n",
    "        \n",
    "def create_new_column(df: pd.DataFrame,function):\n",
    "    \"\"\"\n",
    "    This function is used to sendback a new column using the function apply\n",
    "    and applying function to the elements \n",
    "    \"\"\"\n",
    "    return df.apply(function,axis = 1)\n",
    "\n",
    "def keep_used_odd(df_Données_Promos,df_odd,n) :\n",
    "    \"\"\"\n",
    "    This function delete all the promos which are not used enough\n",
    "    \"\"\"\n",
    "    df_join_odd = join_dataFrames(df_Données_Promos,df_odd,['CPROMO'])\n",
    "\n",
    "    series_count = df_join_odd.groupby(['CPROMO'])['ID_ABONNE'].count() #count the number of people who used each PROMO\n",
    "    series_count = series_count.sort_values(ascending=False) #sort the number of people\n",
    "    series_count = series_count[series_count > n ] # Keep the more used\n",
    "    series_count = series_count.rename('NOMBRE_UTILISATION') # Rename with a proper name\n",
    "\n",
    "    df_filtered_groups = series_count.reset_index() # series to Data fram\n",
    "    df_new_odd = join_dataFrames(df_filtered_groups,df_odd,['CPROMO'])\n",
    "\n",
    "    return df_new_odd\n",
    "\n",
    "def str_to_date(df,col_name):\n",
    "    return pd.to_datetime(df[col_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "#1)\n",
    "\n",
    "def creation_df_odd() :\n",
    "    \"\"\"\n",
    "    This function creates the new df_odd on your Computer\n",
    "    \"\"\"\n",
    "    df_Correspondances_Promos = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Correspondances_Promos.csv\") \n",
    "\n",
    "    df_odd = df_filter_condition(df_Correspondances_Promos,'TYPE_PROMO','ODD') #we create a DataFrame with only ODD Promotion\n",
    "    df_odd['TYPE_PROMON'] = create_new_column(df_odd,apply_conditions) #we create new columns on this DataFrame of the ODD type\n",
    "\n",
    "\n",
    "    #creation df_odd_2021\n",
    "    df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "\n",
    "    n = df_Données_Promos_2021.shape[0] / 10000 #number minimum of used\n",
    "    df_new_odd = keep_used_odd(df_Données_Promos_2021,df_odd,n) #creation of the new tab by keeping only the used promos\n",
    "    \n",
    "    save_to_csv_file(df_new_odd,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    "\n",
    "    #creation df_odd_2022  \n",
    "    df_Données_Promos_2022 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2022.csv\")\n",
    "\n",
    "    n = df_Données_Promos_2022.shape[0] / 10000 #number minimum of used\n",
    "    df_new_odd = keep_used_odd(df_Données_Promos_2022,df_odd,n) #creation of the new tab by keeping only the used promos\n",
    "    \n",
    "    save_to_csv_file(df_new_odd,\"//Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2022.csv\")\n",
    "    \n",
    "    #creation df_odd_2023\n",
    "    df_Données_Promos_2023 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2023.csv\")\n",
    "\n",
    "    n = df_Données_Promos_2023.shape[0] / 10000 #number minimum of used\n",
    "    df_new_odd = keep_used_odd(df_Données_Promos_2023,df_odd,n) #creation of the new tab by keeping only the used promos\n",
    "    \n",
    "    save_to_csv_file(df_new_odd,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2023.csv\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_date(df,col_name):\n",
    "    return pd.to_datetime(df[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TYPE_PROMON\n",
       "Autres                       343172\n",
       "ODD 15 jours EV+              83607\n",
       "ODD 15 jours TC             1375984\n",
       "ODD 21 jours EV+              68290\n",
       "ODD 7 jours autre que SG      39041\n",
       "Semaine genéreuse           2340995\n",
       "Name: ID_ABONNE, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    "df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "df_join = join_dataFrames(df_Données_Promos_2021,df_odd_new,['CPROMO'])\n",
    "series = df_join.groupby('TYPE_PROMON')['ID_ABONNE'].count()\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TYPE_PROMON\n",
       "Autres                       785020\n",
       "ODD 15 jours EV+               6883\n",
       "ODD 15 jours TC             1796235\n",
       "ODD 21 jours EV+             210628\n",
       "ODD 7 jours autre que SG      52213\n",
       "Semaine genéreuse           3067877\n",
       "Name: ID_ABONNE, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Données_Promos_2022 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2022.csv\")\n",
    "df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2022.csv\")\n",
    "df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "df_join = join_dataFrames(df_Données_Promos_2022,df_odd_new,['CPROMO'])\n",
    "series = df_join.groupby('TYPE_PROMON')['ID_ABONNE'].count()\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TYPE_PROMON\n",
       "Autres                       130807\n",
       "ODD 15 jours EV+               9736\n",
       "ODD 15 jours TC             1998454\n",
       "ODD 21 jours EV+             155165\n",
       "ODD 7 jours autre que SG      34033\n",
       "Semaine genéreuse           2543931\n",
       "Name: ID_ABONNE, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Données_Promos_2023 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2023.csv\")\n",
    "df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2023.csv\")\n",
    "df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "df_join = join_dataFrames(df_Données_Promos_2023,df_odd_new,['CPROMO'])\n",
    "series = df_join.groupby('TYPE_PROMON')['ID_ABONNE'].count()\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "# Filtrer par type de promo, nouvelle colonne ? \n",
    "\n",
    "def df_mois_annee(df) :\n",
    "\n",
    "    df['DATE_ACTE_REEL'] = pd.to_datetime(df['DATE_ACTE_REEL'])\n",
    "    \n",
    "    df['MONTH'] = df['DATE_ACTE_REEL'].dt.month\n",
    "    df['YEAR'] = df['DATE_ACTE_REEL'].dt.year\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exo 2 Test pour 'CANAL_DISTRIB' à faire en +  : Enregistrer sur un csv + run pour les autres conditions \n",
    "\n",
    "def repartition_reabo_2021():\n",
    "\n",
    "    df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "    df_Données_Reabos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    "    df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    "    df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "    df_join = join_dataFrames(df_Données_Promos_2021,df_odd_new,['CPROMO'])\n",
    "    df_join = join_dataFrames(df_join,df_Données_Reabos_2021,['ID_ABONNE','DATE_ACTE_REEL'])\n",
    "    df_join = df_mois_annee(df_join)\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON', 'CANAL_DISTRIB'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/type_promo_canaldistrib.csv\")\n",
    "\n",
    "    series = df_join.groupby(['MONTH', 'YEAR', 'CANAL_DISTRIB'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/month_canaldistrib.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH', 'YEAR', 'CANAL_DISTRIB'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_canaldistrib.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH','YEAR', 'REGION'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_region.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH','YEAR', 'SECTEUR'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_secteur.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH','YEAR', 'ENSEIGNE'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_enseigne.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH','YEAR', 'MOYEN_PAIEMENT'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_moypay.csv\")\n",
    "\n",
    "    series = df_join.groupby(['TYPE_PROMON','MONTH','YEAR', 'FORMULE_PREC'])['ID_ABONNE'].count()\n",
    "    df_filtered_groups = series.reset_index(name = 'NB')\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/repartition_formule.csv\")\n",
    "\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE_PROMON</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autres</td>\n",
       "      <td>1</td>\n",
       "      <td>38216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autres</td>\n",
       "      <td>2</td>\n",
       "      <td>19186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autres</td>\n",
       "      <td>3</td>\n",
       "      <td>14696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autres</td>\n",
       "      <td>4</td>\n",
       "      <td>4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autres</td>\n",
       "      <td>5</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Autres</td>\n",
       "      <td>6</td>\n",
       "      <td>60431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Autres</td>\n",
       "      <td>7</td>\n",
       "      <td>25090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autres</td>\n",
       "      <td>8</td>\n",
       "      <td>5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Autres</td>\n",
       "      <td>9</td>\n",
       "      <td>3378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Autres</td>\n",
       "      <td>10</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Autres</td>\n",
       "      <td>11</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Autres</td>\n",
       "      <td>12</td>\n",
       "      <td>38522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ODD 15 jours EV+</td>\n",
       "      <td>4</td>\n",
       "      <td>5733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ODD 15 jours EV+</td>\n",
       "      <td>5</td>\n",
       "      <td>78048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>1</td>\n",
       "      <td>349592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>3</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>4</td>\n",
       "      <td>5687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>5</td>\n",
       "      <td>8187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>6</td>\n",
       "      <td>69072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>7</td>\n",
       "      <td>316672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>8</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>11</td>\n",
       "      <td>141461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ODD 15 jours TC</td>\n",
       "      <td>12</td>\n",
       "      <td>334982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>2</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>3</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>4</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>8</td>\n",
       "      <td>3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>9</td>\n",
       "      <td>13039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>10</td>\n",
       "      <td>14537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>11</td>\n",
       "      <td>13608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ODD 21 jours EV+</td>\n",
       "      <td>12</td>\n",
       "      <td>20806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>1</td>\n",
       "      <td>10115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>2</td>\n",
       "      <td>5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>3</td>\n",
       "      <td>1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>4</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>5</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>6</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>7</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>8</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>9</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>10</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>11</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ODD 7 jours autre que SG</td>\n",
       "      <td>12</td>\n",
       "      <td>2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>1</td>\n",
       "      <td>196056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>2</td>\n",
       "      <td>191897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>3</td>\n",
       "      <td>202978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>4</td>\n",
       "      <td>196677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>5</td>\n",
       "      <td>186648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>6</td>\n",
       "      <td>150648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>7</td>\n",
       "      <td>7847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>8</td>\n",
       "      <td>165763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>9</td>\n",
       "      <td>184108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>10</td>\n",
       "      <td>178219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>11</td>\n",
       "      <td>195891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Semaine genéreuse</td>\n",
       "      <td>12</td>\n",
       "      <td>174540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TYPE_PROMON  MONTH      NB\n",
       "0                     Autres      1   38216\n",
       "1                     Autres      2   19186\n",
       "2                     Autres      3   14696\n",
       "3                     Autres      4    4153\n",
       "4                     Autres      5    1454\n",
       "5                     Autres      6   60431\n",
       "6                     Autres      7   25090\n",
       "7                     Autres      8    5833\n",
       "8                     Autres      9    3378\n",
       "9                     Autres     10    2454\n",
       "10                    Autres     11    1866\n",
       "11                    Autres     12   38522\n",
       "12          ODD 15 jours EV+      4    5733\n",
       "13          ODD 15 jours EV+      5   78048\n",
       "14           ODD 15 jours TC      1  349592\n",
       "15           ODD 15 jours TC      2     257\n",
       "16           ODD 15 jours TC      3    1263\n",
       "17           ODD 15 jours TC      4    5687\n",
       "18           ODD 15 jours TC      5    8187\n",
       "19           ODD 15 jours TC      6   69072\n",
       "20           ODD 15 jours TC      7  316672\n",
       "21           ODD 15 jours TC      8    1090\n",
       "22           ODD 15 jours TC      9      35\n",
       "23           ODD 15 jours TC     10      31\n",
       "24           ODD 15 jours TC     11  141461\n",
       "25           ODD 15 jours TC     12  334982\n",
       "26         ODD 21 jours EV+       1     588\n",
       "27         ODD 21 jours EV+       2     582\n",
       "28         ODD 21 jours EV+       3     683\n",
       "29         ODD 21 jours EV+       4     315\n",
       "30         ODD 21 jours EV+       8    3292\n",
       "31         ODD 21 jours EV+       9   13039\n",
       "32         ODD 21 jours EV+      10   14537\n",
       "33         ODD 21 jours EV+      11   13608\n",
       "34         ODD 21 jours EV+      12   20806\n",
       "35  ODD 7 jours autre que SG      1   10115\n",
       "36  ODD 7 jours autre que SG      2    5344\n",
       "37  ODD 7 jours autre que SG      3    1468\n",
       "38  ODD 7 jours autre que SG      4    1396\n",
       "39  ODD 7 jours autre que SG      5    1120\n",
       "40  ODD 7 jours autre que SG      6    1448\n",
       "41  ODD 7 jours autre que SG      7    3300\n",
       "42  ODD 7 jours autre que SG      8    5457\n",
       "43  ODD 7 jours autre que SG      9    2553\n",
       "44  ODD 7 jours autre que SG     10    2923\n",
       "45  ODD 7 jours autre que SG     11    1322\n",
       "46  ODD 7 jours autre que SG     12    2368\n",
       "47         Semaine genéreuse      1  196056\n",
       "48         Semaine genéreuse      2  191897\n",
       "49         Semaine genéreuse      3  202978\n",
       "50         Semaine genéreuse      4  196677\n",
       "51         Semaine genéreuse      5  186648\n",
       "52         Semaine genéreuse      6  150648\n",
       "53         Semaine genéreuse      7    7847\n",
       "54         Semaine genéreuse      8  165763\n",
       "55         Semaine genéreuse      9  184108\n",
       "56         Semaine genéreuse     10  178219\n",
       "57         Semaine genéreuse     11  195891\n",
       "58         Semaine genéreuse     12  174540"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"\"\"\n",
    " df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    " df_Données_Reabos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    " df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    " df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    " df_join = join_dataFrames(df_Données_Promos_2021,df_odd_new,['CPROMO'])\n",
    " df_join = join_dataFrames(df_join,df_Données_Reabos_2021,['ID_ABONNE','DATE_ACTE_REEL'])\n",
    " df_join = df_mois_annee(df_join)\n",
    "\n",
    " series = df_join.groupby(['TYPE_PROMON', 'MONTH'])['ID_ABONNE'].count()\n",
    " df_filtered_groups = series.reset_index(name = 'NB')\n",
    " df_filtered_groups\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartition_reabo_2021()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "print(df_join.groupby(['TYPE_PROMON','CANAL_DISTRIB'])['ID_ABONNE'].count())\n",
    "print(df_join.groupby(['MONTH','CANAL_DISTRIB'])['ID_ABONNE'].count())\n",
    "print(df_join.groupby(['TYPE_PROMON','MONTH','CANAL_DISTRIB'])['ID_ABONNE'].count())\n",
    "\"\"\"   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)\n",
    "\n",
    "def str_to_date(df,col_name):\n",
    "    return pd.to_datetime(df[col_name])\n",
    "\n",
    "\n",
    "def time_reabo_columns(df,end_abo,date_reabo):\n",
    "    \"\"\"\n",
    "    This function creates a column which represents the delay between the end \n",
    "    of the last abo and  the act of reabo\n",
    "    \"\"\"\n",
    "    df[date_reabo] = str_to_date(df,date_reabo)\n",
    "    df[end_abo] = str_to_date(df,end_abo)\n",
    "    return (df[date_reabo] - df[end_abo]).dt.days\n",
    "\n",
    "def count_abo_conditions(df,name_col,cond):\n",
    "    \"\"\"\n",
    "    This function count the number of elements of the condition and group by\n",
    "    the column \n",
    "    \"\"\"\n",
    "    return df.groupby(name_col)[cond].count()\n",
    "\n",
    "def mean_time_reabo(df,name_col,cond):\n",
    "    \"\"\"\n",
    "    This function calculate the mean of the condition and group by\n",
    "    the column \n",
    "    \"\"\"\n",
    "    return df.groupby([name_col])[cond].mean()\n",
    "\n",
    "def mean_empty_col(df,col,cond):\n",
    "    \"\"\"\n",
    "    This function calculate the mean of the datas of column col by dividing\n",
    "    between the datas where the columns cond is empty or not    \n",
    "    \"\"\"\n",
    "    groupes = df.groupby(df[col].isna())\n",
    "    return groupes[cond].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Application \n",
    "\n",
    "def repartition_reabo_type():\n",
    "\n",
    "    df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "    df_Données_Reabos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    "    df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    "    df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "    df_Données_Promos_2021 = join_dataFrames(df_odd_new,df_Données_Promos_2021,['CPROMO'])\n",
    "\n",
    "\n",
    "    end_abo = 'DATE_FIN_ABO_PREC'\n",
    "    date_reabo = 'DATE_ACTE_REEL'\n",
    "\n",
    "    df_Données_Reabos_2021['TIME_REABO'] = time_reabo_columns(df_Données_Reabos_2021,end_abo,date_reabo) #Creation new colum \"TIME_REABO\"\n",
    "\n",
    "    df_Données_Promos_2021['DATE_ACTE_REEL'] = str_to_date(df_Données_Promos_2021,'DATE_ACTE_REEL') #Preparation join df_Données_Promos_2021 et df_Données_Reabos_2021\n",
    "    df_join = join_dataFrames(df_Données_Promos_2021,df_Données_Reabos_2021,['ID_ABONNE','DATE_ACTE_REEL']) #Join df_Données_Promos_2021 et df_Données_Reabos_2021\n",
    "\n",
    "    series_count = mean_time_reabo(df_join,'TYPE_PROMON','TIME_REABO') #Creation of a Serie with the mean of the Reabo by CPROMO\n",
    "    df_filtered_groups = series_count.reset_index() #Changing Series into a  DataFrame \n",
    "\n",
    "    df_filtered_groups = df_filtered_groups.sort_values(by = 'TIME_REABO', ascending=False)\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/mean_time_reabo_promos.csv\") # Save on My Mac\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Application \n",
    "\n",
    "def repartition_reabo_code():\n",
    "\n",
    "    df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "    df_Données_Reabos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    "    df_odd = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/odd_2021.csv\")\n",
    "    df_odd_new = df_odd[['CPROMO','TYPE_PROMON']] \n",
    "\n",
    "    df_Données_Promos_2021 = join_dataFrames(df_odd_new,df_Données_Promos_2021,['CPROMO'])\n",
    "\n",
    "\n",
    "    end_abo = 'DATE_FIN_ABO_PREC'\n",
    "    date_reabo = 'DATE_ACTE_REEL'\n",
    "\n",
    "    df_Données_Reabos_2021['TIME_REABO'] = time_reabo_columns(df_Données_Reabos_2021,end_abo,date_reabo) #Creation new colum \"TIME_REABO\"\n",
    "\n",
    "    df_Données_Promos_2021['DATE_ACTE_REEL'] = str_to_date(df_Données_Promos_2021,'DATE_ACTE_REEL') #Preparation join df_Données_Promos_2021 et df_Données_Reabos_2021\n",
    "    df_join = join_dataFrames(df_Données_Promos_2021,df_Données_Reabos_2021,['ID_ABONNE','DATE_ACTE_REEL']) #Join df_Données_Promos_2021 et df_Données_Reabos_2021\n",
    "\n",
    "    series_count = mean_time_reabo(df_join,'CPROMO','TIME_REABO') #Creation of a Serie with the mean of the Reabo by CPROMO\n",
    "    df_filtered_groups = series_count.reset_index() #Changing Series into a  DataFrame \n",
    "\n",
    "    df_filtered_groups = df_filtered_groups.sort_values(by = 'TIME_REABO', ascending=False)\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups,\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/mean_time_reabo_codes.csv\") # Save on My Mac\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def comparaison_time_reabo():\n",
    "\n",
    "\n",
    "    df_Données_Promos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Promos_2021.csv\")\n",
    "    df_Données_Reabos_2021 = file_to_dataframe(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    "\n",
    "    end_abo = 'DATE_FIN_ABO_PREC'\n",
    "    date_reabo = 'DATE_ACTE_REEL'\n",
    "\n",
    "    df_Données_Reabos_2021['TIME_REABO'] = time_reabo_columns(df_Données_Reabos_2021,end_abo,date_reabo) #Creation new colum \"TIME_REABO\"\n",
    "\n",
    "    df_Données_Promos_2021['DATE_ACTE_REEL'] = str_to_date(df_Données_Promos_2021,'DATE_ACTE_REEL') #Preparation join df_Données_Promos_2021 et df_Données_Reabos_2021\n",
    "\n",
    "    df_join = join_dataFrames_outer(df_Données_Promos_2021,df_Données_Reabos_2021,['ID_ABONNE','DATE_ACTE_REEL']) #Join df_Données_Promos_2021 et df_Données_Reabos_2021 keeping the empty cases\n",
    "\n",
    "    print(mean_empty_col(df_join,'CPROMO','TIME_REABO')) #Mean time for reabo with and without promotions False mean is promo True mean Na, On peut présenter mieux\n",
    "\n",
    "    return True\n",
    "                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartition_reabo_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartition_reabo_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPROMO\n",
      "False     9.386528\n",
      "True     15.479839\n",
      "Name: TIME_REABO, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparaison_time_reabo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "#Répartition des réabonnements par taux de consommation (12 mois glissants) par type de promotions et hors promotion\n",
    "\n",
    "def taux_consommation():\n",
    "    # Charger le DataFrame à partir du fichier CSV\n",
    "    df_Données_Reabos_2021 = pd.read_csv(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2021.csv\")\n",
    "\n",
    "    # Compter le nombre de fois où chaque abonné est abonné\n",
    "    series_count = df_Données_Reabos_2021.groupby(['ID_ABONNE'])['ID_ABONNE'].count()\n",
    "\n",
    "    # Créer un DataFrame avec le nombre d'abonnements par abonné\n",
    "    df_filtered_groups = series_count.reset_index(name='NB_ABOS')\n",
    "\n",
    "    # Compter le nombre d'abonnés pour chaque nombre d'abonnements\n",
    "    series_count = df_filtered_groups.groupby('NB_ABOS')['NB_ABOS'].count()\n",
    "    df_filtered_groups = series_count.reset_index(name='TOTAL_ABO')\n",
    "\n",
    "    df_filtered_groups = df_filtered_groups.sort_values(by = 'TOTAL_ABO', ascending=False)\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups, \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/nb_reabo_2021.csv\")\n",
    "\n",
    "    # 2022\n",
    "\n",
    "    df_Données_Reabos_2022 = pd.read_csv(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Réabos_2022.csv\")\n",
    "\n",
    "    series_count = df_Données_Reabos_2022.groupby(['ID_ABONNE'])['ID_ABONNE'].count()\n",
    "\n",
    "    df_filtered_groups = series_count.reset_index(name='NB_ABOS')\n",
    "\n",
    "    series_count = df_filtered_groups.groupby('NB_ABOS')['NB_ABOS'].count()\n",
    "    df_filtered_groups = series_count.reset_index(name='TOTAL_ABO')\n",
    "\n",
    "    df_filtered_groups = df_filtered_groups.sort_values(by = 'TOTAL_ABO', ascending=False)\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups, \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/nb_reabo_2022.csv\")\n",
    "\n",
    "    # 2023\n",
    "\n",
    "    df_Données_Reabos_2023 = pd.read_csv(\"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Données_Reabos_2023.csv\")\n",
    "\n",
    "    series_count = df_Données_Reabos_2023.groupby(['ID_ABONNE'])['ID_ABONNE'].count()\n",
    "\n",
    "    df_filtered_groups = series_count.reset_index(name='NB_ABOS')\n",
    "\n",
    "    series_count = df_filtered_groups.groupby('NB_ABOS')['NB_ABOS'].count()\n",
    "    df_filtered_groups = series_count.reset_index(name='TOTAL_ABO')\n",
    "\n",
    "    df_filtered_groups = df_filtered_groups.sort_values(by = 'TOTAL_ABO', ascending=False)\n",
    "\n",
    "    save_to_csv_file(df_filtered_groups, \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/nb_reabo_2023.csv\")\n",
    "\n",
    "    return True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
