{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/\"\n",
    "path_results_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour nettoyer les datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tool_Functions.cleaning_data import *\n",
    "from Tool_Functions.join_data import *\n",
    "from Tool_Functions.test_comportment_reabo import *\n",
    "from Tool_Functions.visual import *\n",
    "from Tool_Functions.comportment_reabo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_clean(data_path):\n",
    "    \"\"\"\n",
    "    Download clean files in your data_path\n",
    "    There has to be the dirty files in your data_path\n",
    "    \"\"\"\n",
    "    df = file_to_dataframe(data_path + \"Correspondances_Promos.csv\",\";\")\n",
    "    df_Correspondances_Promos = change_dates_all(df,['DEBVAL', 'FINVAL', 'DEBABOMIN', 'DEBABOMAX'])\n",
    "    save_to_csv_file(df_Correspondances_Promos,data_path + \"df_Correspondances_Promos.csv\")\n",
    "\n",
    "    for i in range(1, 4, 1):\n",
    "        df = file_to_dataframe(data_path + f\"Donnees_Promos_202{i}.csv\",\",\")\n",
    "        df_Donnees_Promos_202i = clean_dates(df)\n",
    "        save_to_csv_file(df_Donnees_Promos_202i, data_path + f\"df_Donnees_Promos_202{i}.csv\")\n",
    "\n",
    "        df = file_to_dataframe(data_path + f\"Donnees_Reabos_202{i}.csv\",\",\")\n",
    "        df_Donnees_Reabos_202i = clean_dates(df)\n",
    "        save_to_csv_file(df_Donnees_Reabos_202i,data_path + f\"df_Donnees_Reabos_202{i}.csv\")\n",
    "\n",
    "    return\n",
    "\n",
    "def concat_all_years(data_path):\n",
    "    \"\"\"\n",
    "    Create new csv files that concats the 3 years at once.\n",
    "    \"\"\"\n",
    "    for name in [\"df_Donnees_Promos_202\", \"df_Donnees_Reabos_202\"]:\n",
    "        df1 = file_to_dataframe(data_path + name + \"1.csv\",\",\")\n",
    "        df2 = file_to_dataframe(data_path + name + \"2.csv\",\",\")\n",
    "        df3 = file_to_dataframe(data_path + name + \"3.csv\",\",\")\n",
    "\n",
    "        df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "        df.to_csv(data_path + name[:-4] + \".csv\", index = True)\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "upload_clean(path_antoine)\n",
    "concat_all_years(path_antoine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie sur les ODD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_df_odd(data_path, data_path_results):\n",
    "    \"\"\"\n",
    "    This function creates the new df_odd on your Computer where all the ODD are presented and classified with their type\n",
    "    \"\"\"\n",
    "\n",
    "    df_Correspondances_Promos = file_to_dataframe(data_path + \"df_Correspondances_Promos.csv\",\",\") \n",
    "\n",
    "    df_odd = df_filter_condition(df_Correspondances_Promos,'TYPE_PROMO','ODD') #we create a DataFrame with only ODD Promotion\n",
    "    df_odd['TYPE_PROMON'] = create_new_column(df_odd,apply_conditions) #we create new columns on this DataFrame of the ODD type\n",
    "\n",
    "\n",
    "    for i in [1, 2, 3]:\n",
    "    #creation df_odd_202i pour chaque année\n",
    "        df_Donnees_Promos_202i = file_to_dataframe(data_path + f\"df_Donnees_Promos_202{i}.csv\",\",\")\n",
    "\n",
    "        n = df_Donnees_Promos_202i.shape[0] / 10000 #number minimum of used\n",
    "        df_new_odd = keep_used_odd(df_Donnees_Promos_202i,df_odd,n) #creation of the new tab by keeping only the used promos\n",
    "        \n",
    "        save_to_csv_file(df_new_odd,data_path_results + f\"odd_202{i}.csv\")\n",
    "    \n",
    "    #idem sur les trois années\n",
    "    df_Donnees_Promos = file_to_dataframe(data_path + \"df_Donnees_Promos.csv\",\",\")\n",
    "\n",
    "    n = df_Donnees_Promos.shape[0] / 10000 #number minimum of used\n",
    "    df_new_odd = keep_used_odd(df_Donnees_Promos,df_odd,n) #creation of the new tab by keeping only the used promos\n",
    "    \n",
    "    save_to_csv_file(df_new_odd,data_path_results + f\"odd.csv\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "#Intermediary step we change the df_Données_Promos by adding a column 'TYPE_PROMON' for being easier to understand instead of 'CPROMO'\n",
    "\n",
    "def create_df_Données_Promos_odd(data_path, data_path_results):\n",
    "\n",
    "\n",
    "    for i in [1, 2, 3]:\n",
    "        #année i\n",
    "        df_Donnees_Promos_202i = file_to_dataframe(data_path + f\"df_Donnees_Promos_202{i}.csv\",\",\")\n",
    "        df_odd = file_to_dataframe(data_path + f\"odd_202{i}.csv\", \",\")\n",
    "        df_Donnees_Promos_202i_odd = join_dataFrames(df_Donnees_Promos_202i,df_odd[['CPROMO','TYPE_PROMON']] ,'CPROMO') #We create a new column 'TYPE_PROMON' on df_Données_Promos_202i\n",
    "        save_to_csv_file(df_Donnees_Promos_202i_odd,data_path_results + f\"df_Donnees_Promos_202{i}_odd.csv\") #we save it on your Mac\n",
    "\n",
    "    return True\n",
    "\n",
    "def create_df_Données_Promos_odd_all(data_path, data_path_results):\n",
    "    \"\"\"\n",
    "    This function create df_Données_Promos_odd for the dataFrame with all years\n",
    "    \"\"\"\n",
    "    \n",
    "    df_Donnees_Promos = file_to_dataframe(data_path + \"df_Donnees_Promos.csv\",\",\")\n",
    "    df_odd = file_to_dataframe(data_path + \"odd.csv\", \",\")\n",
    "    df_Donnees_Promos_odd = join_dataFrames(df_Donnees_Promos,df_odd[['CPROMO','TYPE_PROMON']] ,'CPROMO') #We create a new column 'TYPE_PROMON' on df_Données_Promos_202i\n",
    "    save_to_csv_file(df_Donnees_Promos_odd,data_path_results + \"df_Donnees_Promos_odd.csv\") #we save it on your Mac\n",
    "    \n",
    "    return True\n",
    "\n",
    "#Intermediary step we create df_Données_Réabos_odd where there are all the Reabos which corresponds to a reabo\n",
    "\n",
    "def create_df_Données_Reabos_odd_all(data_path, data_path_results):\n",
    "    \"\"\"\n",
    "    This function create df_Données_Reabos_odd with all years of Reabos which corresponds to a use of Promo\n",
    "    and then we drop some unused column\n",
    "    \"\"\"\n",
    "    df_Donnees_Promos_odd = file_to_dataframe(data_path +\"df_Donnees_Promos_odd.csv\" )\n",
    "    df_Donnees_Reabos = file_to_dataframe(data_path + \"df_Donnees_Reabos.csv\")\n",
    "    df_Donnees_Reabos_odd = join_dataFrames(df_Donnees_Promos_odd,df_Donnees_Reabos,['ID_ABONNE','DATE_ACTE_REEL'])\n",
    "\n",
    "    df_Donnees_Reabos_odd = df_Donnees_Reabos_odd.drop(columns = [\"REABO_APRES_ECHEANCE\",\"CPROMO\",\"SECTEUR\",\"PAYS\",\"NUMDIST_PARTENAIRE\",\"NOM_PARTENAIRE\",\"NUMDIST_POINT_DE_VENTE\",\"NOM_POINT_DE_VENTE\"])\n",
    "\n",
    "    end_abo = 'DATE_FIN_ABO_PREC'\n",
    "    date_reabo = 'DATE_ACTE_REEL'\n",
    "\n",
    "    df_Donnees_Reabos_odd = time_reabo_columns(df_Donnees_Reabos_odd,end_abo,date_reabo)\n",
    "    \n",
    "    save_to_csv_file(df_Donnees_Reabos_odd,data_path_results + \"df_Donnees_Reabos_odd.csv\")\n",
    "\n",
    "    return True\n",
    "\n",
    "creation_df_odd(path_antoine,path_results_antoine)\n",
    "create_df_Données_Promos_odd(path_antoine, path_results_antoine)\n",
    "create_df_Données_Promos_odd_all(path_antoine,path_results_antoine)\n",
    "create_df_Données_Reabos_odd_all(path_antoine,path_results_antoine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourcentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repartition_reabo_cond(data_path, data_path_results, action = ['write']):\n",
    "    \"\"\"\n",
    "    This function is used to provide some statistics on the reabo habits.\n",
    "    action is a list of the actions we need to do.\n",
    "    \"\"\"\n",
    "\n",
    "    df_Donnees_Promos_odd = file_to_dataframe(data_path + \"df_Donnees_Promos_odd.csv\") #We open the df_Données_Promos_2021_odd where TYPEPROMO <-> CPROMO\n",
    "    df_Donnees_Reabos = file_to_dataframe(data_path + \"df_Donnees_Reabos.csv\")\n",
    "    df_join = join_dataFrames(df_Donnees_Promos_odd,df_Donnees_Reabos,['ID_ABONNE','DATE_ACTE_REEL']) #We join the tables\n",
    "\n",
    "    df_join = df_mois_annee(df_join,'DATE_ACTE_REEL')\n",
    "\n",
    "    #We compute some statistcs using count_abo_conditions : this functions count the number of an occurence where the datas are group by conditions \n",
    "    df_repartition_promo = count_abo_conditions(df_join,['TYPE_PROMON'],'ID_ABONNE')\n",
    "    df_type_promo_canaldistrib = count_abo_conditions(df_join,['TYPE_PROMON', 'CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_month_canaldistrib = count_abo_conditions(df_join,['MONTH', 'YEAR', 'CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_repartition_canaldistrib = count_abo_conditions(df_join,['TYPE_PROMON','MONTH', 'YEAR', 'CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_repartition_region = count_abo_conditions(df_join,['TYPE_PROMON','MONTH','YEAR', 'REGION'],'ID_ABONNE')\n",
    "    df_repartition_secteur = count_abo_conditions(df_join,['TYPE_PROMON','MONTH','YEAR', 'SECTEUR'],'ID_ABONNE')\n",
    "    df_repartition_enseigne = count_abo_conditions(df_join,['TYPE_PROMON','MONTH','YEAR', 'ENSEIGNE'],'ID_ABONNE')\n",
    "    df_repartition_moypay = count_abo_conditions(df_join,['TYPE_PROMON','MONTH','YEAR', 'MOYEN_PAIEMENT'],'ID_ABONNE')\n",
    "    df_repartition_formule = count_abo_conditions(df_join,['TYPE_PROMON','MONTH','YEAR', 'FORMULE_PREC'],'ID_ABONNE')\n",
    "    \n",
    "    nouns = [\"df_repartition_promo.csv\", \"type_promo_canaldistrib.csv\", \"month_canaldistrib.csv\", \"repartition_canaldistrib.csv\", \"repartition_region.csv\", \"repartition_secteur.csv\", \"repartition_enseigne.csv\", \"repartition_moypay.csv\", \"repartition_formule.csv\"]\n",
    "    with open(data_path_results + 'Files_names.txt', \"w\") as file:\n",
    "        for element in nouns:\n",
    "            file.write(f\"{element}\\n\")\n",
    "\n",
    "    if 'write' in action:\n",
    "        save_to_csv_file(df_repartition_promo,data_path_results + \"df_repartition_promo.csv\")\n",
    "        save_to_csv_file(df_type_promo_canaldistrib,data_path_results + \"type_promo_canaldistrib.csv\")\n",
    "        save_to_csv_file(df_month_canaldistrib,data_path_results + \"month_canaldistrib.csv\")\n",
    "        save_to_csv_file(df_repartition_canaldistrib,data_path_results + \"repartition_canaldistrib.csv\")\n",
    "        save_to_csv_file(df_repartition_region,data_path_results + \"repartition_region.csv\")\n",
    "        save_to_csv_file(df_repartition_secteur,data_path_results + \"repartition_secteur.csv\")\n",
    "        save_to_csv_file(df_repartition_enseigne,data_path_results + \"repartition_enseigne.csv\")\n",
    "        save_to_csv_file(df_repartition_moypay,data_path_results + \"repartition_moypay.csv\")\n",
    "        save_to_csv_file(df_repartition_formule,data_path_results + \"repartition_formule.csv\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartition_reabo_cond(path_antoine, path_results_antoine, action = ['write'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_percentage_one_cond(data_path,data_path_results):\n",
    "    \n",
    "    #open_new df_données_Reabos_odd\n",
    "    df_join = file_to_dataframe(data_path + \"df_Donnees_Reabos_odd.csv\")\n",
    "\n",
    "    #We compute some statistcs using count_abo_conditions : this functions count the number of an occurence where the datas are group by conditions \n",
    "    df_repartition_promo = percent_abo_conditions(df_join,['TYPE_PROMON'],'ID_ABONNE')\n",
    "    df_repartition_canaldistrib = percent_abo_conditions(df_join,['CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_repartition_region = percent_abo_conditions(df_join,['REGION'],'ID_ABONNE')\n",
    "    df_repartition_enseigne = percent_abo_conditions(df_join,['ENSEIGNE'],'ID_ABONNE')\n",
    "    df_repartition_moypay = percent_abo_conditions(df_join,['MOYEN_PAIEMENT'],'ID_ABONNE')\n",
    "    df_repartition_formule = percent_abo_conditions(df_join,['FORMULE_PREC'],'ID_ABONNE')\n",
    "\n",
    "    save_to_csv_file(df_repartition_promo,data_path_results + \"repartition_promo_%.csv\")\n",
    "    save_to_csv_file(df_repartition_canaldistrib,data_path_results + \"repartition_canaldistrib_%.csv\")\n",
    "    save_to_csv_file(df_repartition_region,data_path_results + \"repartition_region_%.csv\")\n",
    "    save_to_csv_file(df_repartition_enseigne,data_path_results + \"repartition_enseigne_%.csv\")\n",
    "    save_to_csv_file(df_repartition_moypay,data_path_results + \"repartition_moypay_%.csv\")\n",
    "    save_to_csv_file(df_repartition_formule,data_path_results + \"repartition_formule_%.csv\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_percentage_one_cond(path_antoine,path_results_antoine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_percentage_multiple_conds(data_path,data_path_results):\n",
    "    \n",
    "    #open_new df_données_Reabos_odd\n",
    "    df_join = file_to_dataframe(data_path + \"df_Donnees_Reabos_odd.csv\")\n",
    "\n",
    "    \n",
    "    #We compute some statistcs using count_abo_conditions : this functions count the number of an occurence where the datas are group by conditions \n",
    "    df_repartition_canaldistrib = percent_abo_conditions_group(df_join,['TYPE_PROMON','CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_repartition_region = percent_abo_conditions_group(df_join,['TYPE_PROMON','REGION'],'ID_ABONNE')\n",
    "    df_repartition_enseigne = percent_abo_conditions_group(df_join,['TYPE_PROMON','ENSEIGNE'],'ID_ABONNE')\n",
    "    df_repartition_moypay = percent_abo_conditions_group(df_join,['TYPE_PROMON','MOYEN_PAIEMENT'],'ID_ABONNE')\n",
    "    df_repartition_formule = percent_abo_conditions_group(df_join,['TYPE_PROMON','FORMULE_PREC'],'ID_ABONNE')\n",
    "\n",
    "    save_to_csv_file(df_repartition_canaldistrib,data_path_results + \"promo_\" + \"repartition_canaldistrib.csv\")\n",
    "    save_to_csv_file(df_repartition_region,data_path_results +  \"promo_\" +\"repartition_region.csv\")\n",
    "    save_to_csv_file(df_repartition_enseigne,data_path_results + \"promo_\" + \"repartition_enseigne.csv\")\n",
    "    save_to_csv_file(df_repartition_moypay,data_path_results  + \"promo_\"+ \"repartition_moypay.csv\")\n",
    "    save_to_csv_file(df_repartition_formule,data_path_results + \"promo_\" + \"repartition_formule_prec.csv\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_percentage_multiple_conds(path_antoine,path_results_antoine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cond_compare_months_years(data_path, data_path_results):\n",
    "\n",
    "    \"Compare les utilisations d'un type au cours des mois et des années, indépendamment des promos\"\n",
    "    \n",
    "    df_join = file_to_dataframe(data_path + \"df_Donnees_Reabos_odd.csv\")\n",
    "    df_join = df_mois_annee(df_join,'DATE_ACTE_REEL')\n",
    "\n",
    "    df_month_canaldistrib = count_abo_conditions(df_join,['MONTH', 'YEAR', 'CANAL_DISTRIB'],'ID_ABONNE')\n",
    "    df_month_promo = count_abo_conditions(df_join,['MONTH', 'YEAR', 'TYPE_PROMON'],'ID_ABONNE')\n",
    "    df_month_region = count_abo_conditions(df_join,['MONTH', 'YEAR', 'REGION'],'ID_ABONNE')\n",
    "    df_month_enseigne = count_abo_conditions(df_join,['MONTH', 'YEAR', 'ENSEIGNE'],'ID_ABONNE')\n",
    "    df_month_moypay = count_abo_conditions(df_join,['MONTH', 'YEAR', 'MOYEN_PAIEMENT'],'ID_ABONNE')\n",
    "    df_month_formule = count_abo_conditions(df_join,['MONTH', 'YEAR', 'FORMULE_PREC'],'ID_ABONNE')\n",
    "\n",
    "    save_to_csv_file(df_month_canaldistrib,data_path_results + \"month_canaldistrib.csv\")\n",
    "    save_to_csv_file(df_month_promo,data_path_results + \"month_promo.csv\")\n",
    "    save_to_csv_file(df_month_region,data_path_results + \"month_region.csv\")\n",
    "    save_to_csv_file(df_month_enseigne,data_path_results + \"month_enseigne.csv\")\n",
    "    save_to_csv_file(df_month_moypay,data_path_results + \"month_moypay.csv\")\n",
    "    save_to_csv_file(df_month_formule,data_path_results + \"month_formule.csv\") \n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_cond_compare_months_years(path_antoine, path_results_antoine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 mois glissants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
